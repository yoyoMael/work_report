{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.988506 0.765318 0.885526 0.9895889999999999 0.21511599999999997\n",
      "  0.831676 0.9940829999999999 0.988453]\n",
      " [0.857143 0.017819 0.5849979999999999 0.892689 0.617581 0.39261\n",
      "  0.8720030000000001 0.881441]\n",
      " [0.771617 0.004539 0.5632560000000001 0.805172 0.180807 0.494245\n",
      "  0.8335879999999999 0.647406]\n",
      " [0.990605 0.048611 0.948493 0.998107 0.532183 0.9508719999999999 0.99697\n",
      "  0.994337]\n",
      " [0.896552 0.045902 0.5521739999999999 0.975524 0.694329\n",
      "  0.013699000000000001 0.965398 0.970332]\n",
      " [0.903624 nan 0.275 0.78866 0.9756819999999999 0.008596 0.978909\n",
      "  0.886126]\n",
      " [0.402957 nan 0.6542060000000001 0.647303 0.037037 nan 0.750424 0.693182]\n",
      " [0.69163 nan 0.038961 0.652968 0.355748 nan 0.657596 0.27907]]\n",
      "[[0.9914360000000001 0.929775 0.8896229999999999 0.993399 0.293984 1.0\n",
      "  0.99802 0.9960110000000001]\n",
      " [0.8616540000000001 0.020731 0.7249720000000001 0.851519 0.77146\n",
      "  0.876289 0.864667 0.8546469999999999]\n",
      " [0.759482 0.010909 0.6640729999999999 0.87782 0.33248099999999997\n",
      "  0.8488370000000001 0.892157 0.845917]\n",
      " [0.9857889999999999 0.301724 0.9583649999999999 1.0 0.38495300000000005\n",
      "  1.0 1.0 0.9939620000000001]\n",
      " [0.853125 0.4375 0.74269 0.985866 0.578341 0.666667 0.965398 0.978873]\n",
      " [0.9734219999999999 0.0 0.654054 0.978678 1.0 1.0 0.989706 0.812725]\n",
      " [0.446721 0.0 0.735294 0.8432430000000001 0.08642000000000001 0.0\n",
      "  0.756849 0.792208]\n",
      " [0.9874209999999999 0.0 0.461538 1.0 0.493976 nan 0.993151 0.979592]]\n",
      "[[0.985593 0.650295 0.881467 0.985808 0.16961400000000001 0.711853\n",
      "  0.9901770000000001 0.981009]\n",
      " [0.8526790000000001 0.015625 0.49032700000000007 0.938042 0.514881\n",
      "  0.25297600000000003 0.8794639999999999 0.9099700000000001]\n",
      " [0.784145 0.002865 0.489016 0.743631 0.12416400000000001 0.348615\n",
      "  0.782235 0.524355]\n",
      " [0.995468 0.026435000000000004 0.9388219999999999 0.9962219999999999\n",
      "  0.8617819999999999 0.906344 0.993958 0.994713]\n",
      " [0.9446370000000001 0.024221 0.439446 0.965398 0.8685120000000001\n",
      "  0.00692 0.965398 0.961938]\n",
      " [0.8431649999999999 0.0 0.174101 0.660432 0.952518 0.0043170000000000005\n",
      "  0.9683450000000001 0.974101]\n",
      " [0.367003 0.0 0.589226 0.525253 0.023569 0.0 0.744108 0.616162]\n",
      " [0.532203 0.0 0.020339 0.484746 0.277966 0.0 0.491525 0.162712]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# compare recall of ftp-c  ftp-p  p2p database,  2,3,5,6\n",
    "\n",
    "def get_metric(metric):\n",
    "    files = glob.glob('*1.csv')\n",
    "    files.sort()\n",
    "\n",
    "    df = pd.read_csv('lgb_raw_f_1.csv')\n",
    "    clf_names = ['DT', 'GNB', 'KNN', 'LGBM', 'MLP', 'RBFSVM', 'RF', 'XGB']\n",
    "    classes = df['class'][[2,3,5,6]].values\n",
    "\n",
    "    data = classes\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        data = np.c_[data,df[metric.lower()][[2,3,5,6]].values]\n",
    "    data1 = data[:,1:]\n",
    "\n",
    "\n",
    "    files = glob.glob('*2.csv')\n",
    "    files.sort()\n",
    "\n",
    "    df = pd.read_csv('lgb_raw_f_1.csv')\n",
    "    clf_names = ['DT','GNB', 'KNN', 'LGBM', 'MLP', 'RBFSVM', 'RF', 'XGB']\n",
    "    classes = df['class'][[2,3,5,6]].values\n",
    "\n",
    "    data = classes\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        data = np.c_[data,df[metric.lower()][[2,3,5,6]].values]\n",
    "    data2 = data[:,1:]\n",
    "\n",
    "\n",
    "    data = np.r_[data1,data2]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(metric.lower()+'_comp_dt.csv', header = clf_names, index = False)\n",
    "    print(data)\n",
    "\n",
    "get_metric('F1')\n",
    "get_metric('Precision')\n",
    "get_metric('Recall')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data[:,1:]r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
